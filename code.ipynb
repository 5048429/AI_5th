{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/200], Loss: 0.7988011240959167\n",
      "Epoch [1/10], Step [200/200], Loss: 0.5584688186645508\n",
      "Epoch [1/10] Finished Training\n",
      "Accuracy of the model on the validation set: 67.125 %\n",
      "Epoch [2/10], Step [100/200], Loss: 0.6507971286773682\n",
      "Epoch [2/10], Step [200/200], Loss: 0.6159613132476807\n",
      "Epoch [2/10] Finished Training\n",
      "Accuracy of the model on the validation set: 63.75 %\n",
      "Epoch [3/10], Step [100/200], Loss: 0.7071638107299805\n",
      "Epoch [3/10], Step [200/200], Loss: 0.7235562801361084\n",
      "Epoch [3/10] Finished Training\n",
      "Accuracy of the model on the validation set: 70.5 %\n",
      "Epoch [4/10], Step [100/200], Loss: 0.3674232065677643\n",
      "Epoch [4/10], Step [200/200], Loss: 0.20071054995059967\n",
      "Epoch [4/10] Finished Training\n",
      "Accuracy of the model on the validation set: 65.25 %\n",
      "Epoch [5/10], Step [100/200], Loss: 0.9101855158805847\n",
      "Epoch [5/10], Step [200/200], Loss: 1.0329341888427734\n",
      "Epoch [5/10] Finished Training\n",
      "Accuracy of the model on the validation set: 61.625 %\n",
      "Epoch [6/10], Step [100/200], Loss: 0.6803607940673828\n",
      "Epoch [6/10], Step [200/200], Loss: 0.6207922101020813\n",
      "Epoch [6/10] Finished Training\n",
      "Accuracy of the model on the validation set: 63.125 %\n",
      "Epoch [7/10], Step [100/200], Loss: 0.9624748826026917\n",
      "Epoch [7/10], Step [200/200], Loss: 0.874904453754425\n",
      "Epoch [7/10] Finished Training\n",
      "Accuracy of the model on the validation set: 65.25 %\n",
      "Epoch [8/10], Step [100/200], Loss: 0.8199388980865479\n",
      "Epoch [8/10], Step [200/200], Loss: 0.8202042579650879\n",
      "Epoch [8/10] Finished Training\n",
      "Accuracy of the model on the validation set: 65.125 %\n",
      "Epoch [9/10], Step [100/200], Loss: 0.8819740414619446\n",
      "Epoch [9/10], Step [200/200], Loss: 0.7638258337974548\n",
      "Epoch [9/10] Finished Training\n",
      "Accuracy of the model on the validation set: 64.25 %\n",
      "Epoch [10/10], Step [100/200], Loss: 0.5789544582366943\n",
      "Epoch [10/10], Step [200/200], Loss: 0.7478683590888977\n",
      "Epoch [10/10] Finished Training\n",
      "Accuracy of the model on the validation set: 61.25 %\n",
      "Accuracy of the model on the validation set: 61.25 %\n",
      "{'8': 'positive', '1576': 'positive', '2320': 'positive', '4912': 'positive', '3821': 'positive', '1306': 'positive', '4555': 'positive', '259': 'positive', '3216': 'positive', '881': 'positive', '1037': 'positive', '2463': 'positive', '3760': 'positive', '3102': 'positive', '4074': 'positive', '2155': 'positive', '5009': 'negative', '3292': 'positive', '3599': 'positive', '1061': 'negative', '3927': 'negative', '4461': 'positive', '716': 'positive', '2505': 'positive', '1803': 'negative', '2157': 'negative', '1612': 'positive', '4052': 'positive', '3641': 'positive', '5097': 'positive', '2358': 'negative', '349': 'negative', '4710': 'positive', '2991': 'positive', '459': 'negative', '1737': 'positive', '1993': 'positive', '116': 'negative', '2949': 'positive', '2792': 'negative', '1580': 'positive', '2021': 'positive', '4843': 'negative', '4827': 'positive', '3119': 'neutral', '3298': 'negative', '4541': 'positive', '1952': 'positive', '1839': 'negative', '2127': 'negative', '3872': 'positive', '3023': 'positive', '2351': 'positive', '4507': 'negative', '600': 'positive', '1516': 'positive', '4601': 'negative', '1046': 'positive', '1227': 'positive', '4378': 'positive', '4357': 'negative', '4094': 'neutral', '5027': 'positive', '1969': 'positive', '4754': 'positive', '861': 'negative', '136': 'negative', '4466': 'neutral', '4916': 'negative', '1025': 'negative', '4922': 'positive', '1233': 'positive', '1173': 'positive', '532': 'positive', '51': 'positive', '3008': 'negative', '1578': 'negative', '4945': 'positive', '2572': 'positive', '173': 'positive', '3439': 'positive', '755': 'neutral', '2918': 'negative', '1417': 'positive', '3152': 'positive', '121': 'negative', '780': 'negative', '4319': 'negative', '1191': 'neutral', '1573': 'positive', '1406': 'negative', '3955': 'positive', '2904': 'negative', '2721': 'negative', '58': 'positive', '3149': 'negative', '3690': 'positive', '3243': 'positive', '3476': 'positive', '1393': 'positive', '3362': 'positive', '1552': 'positive', '2348': 'positive', '1863': 'positive', '3003': 'positive', '1949': 'positive', '2137': 'positive', '4500': 'negative', '2823': 'positive', '1021': 'positive', '3103': 'positive', '4981': 'positive', '3110': 'positive', '824': 'negative', '1999': 'positive', '1769': 'negative', '4038': 'positive', '2499': 'positive', '4287': 'positive', '4913': 'positive', '3181': 'positive', '4578': 'positive', '1446': 'positive', '1269': 'positive', '2803': 'positive', '1099': 'positive', '96': 'positive', '749': 'positive', '489': 'positive', '3464': 'negative', '4910': 'positive', '5000': 'negative', '2717': 'negative', '939': 'positive', '4944': 'negative', '4560': 'positive', '4471': 'negative', '313': 'negative', '3002': 'positive', '204': 'positive', '4082': 'positive', '960': 'negative', '740': 'negative', '31': 'positive', '3324': 'positive', '264': 'positive', '1922': 'positive', '3424': 'positive', '1192': 'positive', '4603': 'positive', '570': 'positive', '2668': 'negative', '1645': 'positive', '3271': 'positive', '89': 'positive', '3975': 'neutral', '3397': 'positive', '3638': 'neutral', '1228': 'positive', '2744': 'positive', '4545': 'positive', '730': 'negative', '2958': 'positive', '1717': 'positive', '1324': 'positive', '4312': 'positive', '3374': 'positive', '4430': 'positive', '3945': 'positive', '290': 'positive', '4061': 'negative', '1168': 'positive', '1667': 'negative', '3139': 'positive', '964': 'positive', '3495': 'negative', '932': 'positive', '4483': 'positive', '3227': 'negative', '5108': 'negative', '1931': 'positive', '5040': 'positive', '3174': 'positive', '1381': 'negative', '2800': 'positive', '4911': 'negative', '1768': 'positive', '4087': 'negative', '1648': 'positive', '3909': 'positive', '4348': 'positive', '3170': 'negative', '3774': 'positive', '3492': 'positive', '1994': 'positive', '2971': 'positive', '5043': 'negative', '4552': 'positive', '4372': 'positive', '1682': 'positive', '4046': 'negative', '4022': 'positive', '174': 'positive', '4387': 'negative', '677': 'positive', '1133': 'positive', '429': 'positive', '4040': 'positive', '2114': 'positive', '3998': 'negative', '1020': 'positive', '2676': 'positive', '2367': 'positive', '5037': 'positive', '2863': 'positive', '2988': 'positive', '2746': 'negative', '1431': 'positive', '2550': 'negative', '286': 'negative', '739': 'positive', '3348': 'positive', '3948': 'positive', '3224': 'negative', '1096': 'positive', '1584': 'negative', '3660': 'positive', '3898': 'positive', '751': 'negative', '3963': 'positive', '3891': 'negative', '312': 'negative', '867': 'negative', '3268': 'negative', '1697': 'negative', '1791': 'negative', '3701': 'negative', '2055': 'positive', '3914': 'positive', '3572': 'negative', '1660': 'negative', '2943': 'negative', '424': 'positive', '1285': 'positive', '3039': 'positive', '1642': 'positive', '1111': 'positive', '1539': 'negative', '3401': 'negative', '2098': 'positive', '3400': 'positive', '4345': 'negative', '1352': 'positive', '4681': 'negative', '3005': 'positive', '2362': 'positive', '2154': 'positive', '1512': 'positive', '2677': 'positive', '848': 'negative', '1243': 'negative', '3637': 'positive', '1990': 'positive', '2627': 'positive', '948': 'positive', '5039': 'positive', '1587': 'positive', '55': 'negative', '4738': 'negative', '4205': 'negative', '3494': 'positive', '2758': 'negative', '479': 'negative', '1898': 'positive', '3046': 'positive', '1088': 'positive', '1039': 'negative', '1875': 'negative', '1100': 'positive', '224': 'positive', '2585': 'neutral', '2888': 'negative', '1309': 'negative', '4693': 'neutral', '3651': 'positive', '383': 'positive', '1057': 'positive', '2607': 'negative', '3306': 'negative', '310': 'neutral', '2646': 'negative', '1490': 'negative', '4860': 'positive', '1606': 'positive', '3554': 'positive', '3580': 'positive', '4947': 'neutral', '3889': 'positive', '5': 'negative', '2704': 'neutral', '3346': 'negative', '2480': 'negative', '3842': 'positive', '4807': 'neutral', '3001': 'positive', '4715': 'positive', '4410': 'positive', '1290': 'positive', '4644': 'negative', '4294': 'positive', '4847': 'positive', '2750': 'positive', '1861': 'positive', '4272': 'positive', '617': 'negative', '1574': 'negative', '2332': 'positive', '1974': 'positive', '3399': 'positive', '3714': 'negative', '5092': 'negative', '2709': 'negative', '1435': 'negative', '4449': 'neutral', '2939': 'positive', '1429': 'positive', '145': 'negative', '250': 'positive', '4871': 'positive', '1868': 'negative', '1508': 'negative', '4811': 'positive', '3222': 'negative', '566': 'negative', '558': 'negative', '38': 'positive', '533': 'negative', '2527': 'positive', '2078': 'negative', '3731': 'positive', '124': 'positive', '4774': 'positive', '967': 'positive', '3016': 'positive', '2911': 'positive', '4613': 'negative', '4201': 'positive', '4877': 'positive', '4306': 'neutral', '3671': 'negative', '4255': 'neutral', '1105': 'negative', '1806': 'negative', '3061': 'negative', '1830': 'negative', '3417': 'positive', '60': 'positive', '1933': 'positive', '3022': 'positive', '2635': 'positive', '2815': 'positive', '1301': 'positive', '575': 'negative', '4925': 'negative', '4112': 'positive', '5127': 'positive', '4795': 'positive', '334': 'negative', '3126': 'positive', '912': 'positive', '3969': 'positive', '3451': 'positive', '3336': 'positive', '923': 'positive', '2737': 'neutral', '2443': 'neutral', '1312': 'positive', '3505': 'negative', '2764': 'positive', '4580': 'negative', '3854': 'positive', '2570': 'positive', '2989': 'positive', '2115': 'positive', '3462': 'negative', '1699': 'neutral', '4898': 'negative', '4138': 'positive', '1866': 'positive', '2915': 'negative', '1635': 'positive', '1908': 'positive', '4030': 'positive', '4771': 'positive', '3248': 'positive', '494': 'positive', '3161': 'positive', '20': 'positive', '3300': 'negative', '4242': 'negative', '1476': 'positive', '1879': 'positive', '1384': 'positive', '1616': 'positive', '4376': 'negative', '3884': 'positive', '2026': 'negative', '4291': 'neutral', '4790': 'positive', '657': 'negative', '2873': 'positive', '812': 'positive', '2893': 'positive', '3296': 'positive', '126': 'positive', '2469': 'positive', '3206': 'positive', '2019': 'positive', '916': 'negative', '4621': 'negative', '1620': 'positive', '184': 'positive', '5017': 'positive', '1201': 'positive', '5111': 'positive', '4417': 'negative', '4431': 'positive', '4434': 'positive', '4920': 'positive', '272': 'negative', '279': 'negative', '3020': 'positive', '2325': 'positive', '2858': 'positive', '4288': 'positive', '1596': 'positive', '803': 'positive', '4363': 'negative', '1895': 'positive', '3044': 'negative', '4721': 'negative', '698': 'positive', '1426': 'positive', '2016': 'positive', '3745': 'positive', '4903': 'positive', '534': 'negative', '3650': 'neutral', '3371': 'positive', '112': 'negative', '176': 'positive', '573': 'negative', '4919': 'positive', '3276': 'positive', '480': 'positive', '87': 'negative', '911': 'negative', '3705': 'positive', '3082': 'positive', '2537': 'positive', '4450': 'neutral', '1497': 'positive', '3083': 'positive', '443': 'positive', '2957': 'negative', '2099': 'positive', '2962': 'positive', '460': 'positive', '1918': 'negative', '3052': 'negative', '13': 'positive', '863': 'negative', '1252': 'negative', '3570': 'positive', '4684': 'negative', '2046': 'negative', '1537': 'negative', '2555': 'positive', '1052': 'positive', '1713': 'positive', '2597': 'positive', '282': 'positive', '3833': 'negative', '4885': 'positive', '4587': 'negative', '1401': 'positive', '1281': 'positive', '2085': 'positive', '565': 'negative', '1205': 'positive', '1560': 'positive', '4064': 'negative', '1036': 'negative', '2606': 'positive', '4777': 'negative', '588': 'positive', '609': 'negative', '3279': 'positive', '3511': 'positive', '4796': 'neutral', '2107': 'negative', '1106': 'positive', '3395': 'negative', '2546': 'positive', '4678': 'positive', '1000': 'positive', '1048': 'positive', '1059': 'positive', '1485': 'negative', '3195': 'negative', '2029': 'negative'}\n",
      "预测结果已保存到文件：predicted_labels_0128.txt\n"
     ]
    }
   ],
   "source": [
    "# 多模态模型\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# 数据加载部分\n",
    "def load_labels(filename):\n",
    "    labels = {}\n",
    "    with open(filename, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        next(reader)  # 跳过标题行\n",
    "        for row in reader:\n",
    "            guid, tag = row\n",
    "            labels[guid] = tag\n",
    "    return labels\n",
    "\n",
    "def load_data(data_dir, labels):\n",
    "    data = []\n",
    "    for guid, tag in labels.items():\n",
    "        text_file = os.path.join(data_dir, f\"{guid}.txt\")\n",
    "        image_file = os.path.join(data_dir, f\"{guid}.jpg\")\n",
    "\n",
    "        # 读取文本数据\n",
    "        with open(text_file, 'r', encoding='utf-8', errors='replace') as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "        # 读取图像数据\n",
    "        image_data = Image.open(image_file)\n",
    "\n",
    "        data.append((guid, text_data, image_data, tag))\n",
    "    return data\n",
    "\n",
    "# 使用数据加载函数\n",
    "labels = load_labels(\"train.txt\")\n",
    "data_dir = 'data'\n",
    "data = load_data(data_dir, labels)\n",
    "\n",
    "# 划分数据集\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 图像转换函数\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 自定义数据集类\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_text_len=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_text_len = max_text_len\n",
    "        self.label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        _, text, image, tag = self.data[idx]\n",
    "\n",
    "        # 处理图像\n",
    "        image = image_transform(image)\n",
    "\n",
    "        # 处理文本\n",
    "        text = self.tokenizer(text, padding='max_length', max_length=self.max_text_len, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        # 获取标签\n",
    "        label = self.label_mapping[tag]\n",
    "\n",
    "        return image, text, label\n",
    "\n",
    "# 自定义多模态网络类\n",
    "class MultimodalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultimodalNetwork, self).__init__()\n",
    "        self.image_model = models.resnet50(pretrained=True)\n",
    "        self.text_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # 冻结ResNet50的参数\n",
    "        for param in self.image_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # 修改ResNet50的最后一层以提取特征，而不是进行分类\n",
    "        self.image_model.fc = nn.Identity()\n",
    "\n",
    "        # 定义组合特征后的分类层\n",
    "        self.classifier = nn.Linear(2048 + 768, 3)\n",
    "\n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        # 提取图像特征\n",
    "        img_features = self.image_model(images)\n",
    "\n",
    "        # 提取文本特征\n",
    "        text_outputs = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.pooler_output\n",
    "\n",
    "        # 合并特征\n",
    "        combined_features = torch.cat((img_features, text_features), dim=1)\n",
    "\n",
    "        # 分类\n",
    "        logits = self.classifier(combined_features)\n",
    "\n",
    "        return logits\n",
    "\n",
    "# 为训练集和验证集创建 DataLoader\n",
    "train_dataset = MultimodalDataset(train_data, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "val_dataset = MultimodalDataset(val_data, tokenizer)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 模型、损失函数和优化器\n",
    "model = MultimodalNetwork().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (images, texts, labels) in enumerate(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        input_ids = texts['input_ids'].squeeze(1).to(device)\n",
    "        attention_mask = texts['attention_mask'].squeeze(1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_dataloader)}], Loss: {loss.item()}')\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}] Finished Training')\n",
    "\n",
    "    def evaluate_model(model, dataloader, file_name=\"error_analysis.txt\"):\n",
    "        model.eval()  # 设置模型为评估模式\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad(), open(file_name, \"w\") as file:\n",
    "            for images, texts, labels in dataloader:\n",
    "                images = images.to(device)\n",
    "                input_ids = texts['input_ids'].squeeze(1).to(device)\n",
    "                attention_mask = texts['attention_mask'].squeeze(1).to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images, input_ids, attention_mask)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                # 收集并记录错误预测的样本\n",
    "                mismatches = (predicted != labels).nonzero(as_tuple=False)\n",
    "                for idx in mismatches:\n",
    "                    actual_label = labels[idx].item()\n",
    "                    predicted_label = predicted[idx].item()\n",
    "                    file.write(f\"Actual Label: {actual_label}, Predicted Label: {predicted_label}\\n\")\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Accuracy of the model on the validation set: {accuracy} %')\n",
    "\n",
    "    # 在每个epoch后使用修改后的评估函数\n",
    "    evaluate_model(model, val_dataloader)\n",
    "\n",
    "evaluate_model(model, val_dataloader)\n",
    "\n",
    "# 加载测试数据\n",
    "def load_test_data(test_file, data_dir):\n",
    "    test_data = []\n",
    "    with open(test_file, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        next(reader)  # 跳过标题行\n",
    "        for row in reader:\n",
    "            guid = row[0]\n",
    "            text_file = os.path.join(data_dir, f\"{guid}.txt\")\n",
    "            image_file = os.path.join(data_dir, f\"{guid}.jpg\")\n",
    "\n",
    "            # 读取文本数据\n",
    "            with open(text_file, 'r', encoding='utf-8', errors='replace') as file:\n",
    "                text_data = file.read()\n",
    "\n",
    "            # 读取图像数据\n",
    "            image_data = Image.open(image_file)\n",
    "\n",
    "            test_data.append((guid, text_data, image_data))\n",
    "    return test_data\n",
    "\n",
    "test_data = load_test_data('test_without_label.txt', data_dir)\n",
    "\n",
    "# 创建测试数据集\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_text_len=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_text_len = max_text_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        guid, text, image = self.data[idx]\n",
    "\n",
    "        # 处理图像\n",
    "        image = image_transform(image)\n",
    "\n",
    "        # 处理文本\n",
    "        text = self.tokenizer(text, padding='max_length', max_length=self.max_text_len, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        return guid, image, text\n",
    "\n",
    "test_dataset = TestDataset(test_data, tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 预测函数\n",
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = {}\n",
    "    with torch.no_grad():\n",
    "        for guid, images, texts in dataloader:\n",
    "            images = images.to(device)\n",
    "            input_ids = texts['input_ids'].squeeze(1).to(device)\n",
    "            attention_mask = texts['attention_mask'].squeeze(1).to(device)\n",
    "\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            for g, p in zip(guid, predicted):\n",
    "                predictions[g] = p.item()\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# 进行预测\n",
    "model_predictions = predict(model, test_dataloader)\n",
    "\n",
    "# 转换预测结果为标签\n",
    "predicted_labels = {guid: ['negative', 'neutral', 'positive'][label] for guid, label in model_predictions.items()}\n",
    "\n",
    "print(predicted_labels)\n",
    "\n",
    "# 将预测结果写入新文件\n",
    "output_file = 'predicted_labels_0128.txt'\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    file.write('guid,tag\\n')\n",
    "\n",
    "    # 写入预测的标签\n",
    "    for guid, label in predicted_labels.items():\n",
    "        file.write(f'{guid},{label}\\n')\n",
    "\n",
    "print(f'预测结果已保存到文件：{output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch [1/1], Step [100/200], Loss: 1.0511832237243652\n",
      "Epoch [1/1], Step [200/200], Loss: 0.6059260368347168\n",
      "Epoch [1/1] Finished Training\n",
      "Accuracy of the Text Model on the validation set: 76.84375 %\n",
      "Epoch [1/1], Step [100/200], Loss: 0.9519345760345459\n",
      "Epoch [1/1], Step [200/200], Loss: 0.8102669715881348\n",
      "Epoch [1/1] Finished Training\n",
      "Accuracy of the Image Model on the validation set: 61.71875 %\n"
     ]
    }
   ],
   "source": [
    "#消融实验 单个epoch\n",
    "import torch\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# 数据加载部分\n",
    "def load_labels(filename):\n",
    "    labels = {}\n",
    "    with open(filename, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        next(reader)  # 跳过标题行\n",
    "        for row in reader:\n",
    "            guid, tag = row\n",
    "            labels[guid] = tag\n",
    "    return labels\n",
    "\n",
    "def load_data(data_dir, labels):\n",
    "    data = []\n",
    "    for guid, tag in labels.items():\n",
    "        text_file = os.path.join(data_dir, f\"{guid}.txt\")\n",
    "        image_file = os.path.join(data_dir, f\"{guid}.jpg\")\n",
    "        with open(text_file, 'r', encoding='utf-8', errors='replace') as file:\n",
    "            text_data = file.read()\n",
    "        image_data = Image.open(image_file)\n",
    "        data.append((guid, text_data, image_data, tag))\n",
    "    return data\n",
    "\n",
    "labels = load_labels(\"train.txt\")\n",
    "data_dir = 'data'\n",
    "data = load_data(data_dir, labels)\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# 图像转换函数\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 仅文本数据的数据集类\n",
    "class TextOnlyDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_text_len=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_text_len = max_text_len\n",
    "        self.label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        _, text, _, tag = self.data[idx]\n",
    "        text = self.tokenizer(text, padding='max_length', max_length=self.max_text_len, truncation=True, return_tensors=\"pt\")\n",
    "        label = self.label_mapping[tag]\n",
    "        return text, label\n",
    "    \n",
    "class ImageOnlyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        _, _, image, tag = self.data[idx]\n",
    "        image = image_transform(image)\n",
    "        label = self.label_mapping[tag]\n",
    "        return image, label\n",
    "\n",
    "# 仅文本的模型\n",
    "class TextOnlyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextOnlyModel, self).__init__()\n",
    "        self.text_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.classifier = nn.Linear(768, 3) \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        text_outputs = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.pooler_output\n",
    "        logits = self.classifier(text_features)\n",
    "        return logits\n",
    "\n",
    "# 仅图像的模型\n",
    "class ImageOnlyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageOnlyModel, self).__init__()\n",
    "        self.image_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "        # 冻结ResNet50的参数\n",
    "        for param in self.image_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.image_model.fc = nn.Linear(self.image_model.fc.in_features, 3)  # 修改为分类层\n",
    "\n",
    "    def forward(self, images):\n",
    "        logits = self.image_model(images)\n",
    "        return logits\n",
    "\n",
    "# 创建DataLoader\n",
    "text_only_train_dataset = TextOnlyDataset(train_data, tokenizer)\n",
    "text_only_train_dataloader = DataLoader(text_only_train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "image_only_train_dataset = ImageOnlyDataset(train_data)\n",
    "image_only_train_dataloader = DataLoader(image_only_train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# 训练和评估函数\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=1, is_text_model=False):\n",
    "    model.train()  # 将模型设置为训练模式\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            # 如果是文本模型\n",
    "            if is_text_model:\n",
    "                texts, labels = batch\n",
    "                input_ids = texts['input_ids'].squeeze(1).to(device)\n",
    "                attention_mask = texts['attention_mask'].squeeze(1).to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(input_ids, attention_mask)  # 传递正确的参数\n",
    "            else:\n",
    "                # 如果是图像模型\n",
    "                images, labels = batch\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "            # 重置梯度\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 前向传播\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 反向传播和优化\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(dataloader)}], Loss: {loss.item()}')\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}] Finished Training')\n",
    "\n",
    "def evaluate_model(model, dataloader, is_text_model=False):\n",
    "    model_type = \"Text\" if is_text_model else \"Image\"\n",
    "    model.eval()  # 将模型设置为评估模式\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            if is_text_model:\n",
    "                texts, labels = batch\n",
    "                input_ids = texts['input_ids'].squeeze(1).to(device)\n",
    "                attention_mask = texts['attention_mask'].squeeze(1).to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "            else:\n",
    "                images, labels = batch\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the {model_type} Model on the validation set: {accuracy} %')\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "text_model = TextOnlyModel().to(device)\n",
    "image_model = ImageOnlyModel().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "text_optimizer = Adam(text_model.parameters(), lr=1e-4)\n",
    "image_optimizer = Adam(image_model.parameters(), lr=1e-4)\n",
    "\n",
    "# 训练和评估\n",
    "train_model(text_model, text_only_train_dataloader, criterion, text_optimizer, is_text_model=True)\n",
    "evaluate_model(text_model, text_only_train_dataloader, is_text_model=True)\n",
    "\n",
    "\n",
    "train_model(image_model, image_only_train_dataloader, criterion, image_optimizer)\n",
    "evaluate_model(image_model, image_only_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch [1/10], Step [100/200], Loss: 1.0498110055923462\n",
      "Epoch [1/10], Step [200/200], Loss: 0.7482496500015259\n",
      "Epoch [2/10], Step [100/200], Loss: 0.7246271967887878\n",
      "Epoch [2/10], Step [200/200], Loss: 0.7929370403289795\n",
      "Epoch [3/10], Step [100/200], Loss: 0.9160317182540894\n",
      "Epoch [3/10], Step [200/200], Loss: 1.2740421295166016\n",
      "Epoch [4/10], Step [100/200], Loss: 1.007752537727356\n",
      "Epoch [4/10], Step [200/200], Loss: 0.9982258677482605\n",
      "Epoch [5/10], Step [100/200], Loss: 0.9333962202072144\n",
      "Epoch [5/10], Step [200/200], Loss: 1.058244228363037\n",
      "Epoch [6/10], Step [100/200], Loss: 1.0649231672286987\n",
      "Epoch [6/10], Step [200/200], Loss: 1.184614896774292\n",
      "Epoch [7/10], Step [100/200], Loss: 0.991972029209137\n",
      "Epoch [7/10], Step [200/200], Loss: 0.7762249708175659\n",
      "Epoch [8/10], Step [100/200], Loss: 0.9536113739013672\n",
      "Epoch [8/10], Step [200/200], Loss: 1.0249760150909424\n",
      "Epoch [9/10], Step [100/200], Loss: 0.8444915413856506\n",
      "Epoch [9/10], Step [200/200], Loss: 0.8965730667114258\n",
      "Epoch [10/10], Step [100/200], Loss: 0.8346863985061646\n",
      "Epoch [10/10], Step [200/200], Loss: 0.8472128510475159\n",
      "Epoch [10/10] Finished Training\n",
      "Accuracy of the Text Model on the validation set: 59.53125 %\n",
      "Epoch [1/10], Step [100/200], Loss: 0.8700272440910339\n",
      "Epoch [1/10], Step [200/200], Loss: 0.8504122495651245\n",
      "Epoch [2/10], Step [100/200], Loss: 0.6710808873176575\n",
      "Epoch [2/10], Step [200/200], Loss: 0.7716893553733826\n",
      "Epoch [3/10], Step [100/200], Loss: 0.7678555846214294\n",
      "Epoch [3/10], Step [200/200], Loss: 0.678406834602356\n",
      "Epoch [4/10], Step [100/200], Loss: 0.638258159160614\n",
      "Epoch [4/10], Step [200/200], Loss: 0.9293013215065002\n",
      "Epoch [5/10], Step [100/200], Loss: 0.6622889041900635\n",
      "Epoch [5/10], Step [200/200], Loss: 0.5352687835693359\n",
      "Epoch [6/10], Step [100/200], Loss: 0.6722620129585266\n",
      "Epoch [6/10], Step [200/200], Loss: 1.0197017192840576\n",
      "Epoch [7/10], Step [100/200], Loss: 0.46604567766189575\n",
      "Epoch [7/10], Step [200/200], Loss: 0.7727079391479492\n",
      "Epoch [8/10], Step [100/200], Loss: 0.5994027853012085\n",
      "Epoch [8/10], Step [200/200], Loss: 0.7640274167060852\n",
      "Epoch [9/10], Step [100/200], Loss: 0.802619457244873\n",
      "Epoch [9/10], Step [200/200], Loss: 1.0750938653945923\n",
      "Epoch [10/10], Step [100/200], Loss: 0.7786669135093689\n",
      "Epoch [10/10], Step [200/200], Loss: 0.6137496829032898\n",
      "Epoch [10/10] Finished Training\n",
      "Accuracy of the Image Model on the validation set: 68.53125 %\n"
     ]
    }
   ],
   "source": [
    "#消融实验\n",
    "import torch\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# 数据加载部分\n",
    "def load_labels(filename):\n",
    "    labels = {}\n",
    "    with open(filename, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        next(reader)  # 跳过标题行\n",
    "        for row in reader:\n",
    "            guid, tag = row\n",
    "            labels[guid] = tag\n",
    "    return labels\n",
    "\n",
    "def load_data(data_dir, labels):\n",
    "    data = []\n",
    "    for guid, tag in labels.items():\n",
    "        text_file = os.path.join(data_dir, f\"{guid}.txt\")\n",
    "        image_file = os.path.join(data_dir, f\"{guid}.jpg\")\n",
    "        with open(text_file, 'r', encoding='utf-8', errors='replace') as file:\n",
    "            text_data = file.read()\n",
    "        image_data = Image.open(image_file)\n",
    "        data.append((guid, text_data, image_data, tag))\n",
    "    return data\n",
    "\n",
    "labels = load_labels(\"train.txt\")\n",
    "data_dir = 'data'\n",
    "data = load_data(data_dir, labels)\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# 图像转换函数\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 仅文本数据的数据集类\n",
    "class TextOnlyDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_text_len=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_text_len = max_text_len\n",
    "        self.label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        _, text, _, tag = self.data[idx]\n",
    "        text = self.tokenizer(text, padding='max_length', max_length=self.max_text_len, truncation=True, return_tensors=\"pt\")\n",
    "        label = self.label_mapping[tag]\n",
    "        return text, label\n",
    "    \n",
    "class ImageOnlyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        _, _, image, tag = self.data[idx]\n",
    "        image = image_transform(image)\n",
    "        label = self.label_mapping[tag]\n",
    "        return image, label\n",
    "\n",
    "# 仅文本的模型\n",
    "class TextOnlyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextOnlyModel, self).__init__()\n",
    "        self.text_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.classifier = nn.Linear(768, 3)  # 假设BERT的输出维度是768\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        text_outputs = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.pooler_output\n",
    "        logits = self.classifier(text_features)\n",
    "        return logits\n",
    "\n",
    "# 仅图像的模型\n",
    "class ImageOnlyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageOnlyModel, self).__init__()\n",
    "        self.image_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "        # 冻结ResNet50的参数\n",
    "        for param in self.image_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.image_model.fc = nn.Linear(self.image_model.fc.in_features, 3)  # 修改为分类层\n",
    "\n",
    "    def forward(self, images):\n",
    "        logits = self.image_model(images)\n",
    "        return logits\n",
    "\n",
    "# 创建DataLoader\n",
    "text_only_train_dataset = TextOnlyDataset(train_data, tokenizer)\n",
    "text_only_train_dataloader = DataLoader(text_only_train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "image_only_train_dataset = ImageOnlyDataset(train_data)\n",
    "image_only_train_dataloader = DataLoader(image_only_train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# 训练和评估函数\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10, is_text_model=False):\n",
    "    model.train()  # 将模型设置为训练模式\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            # 如果是文本模型\n",
    "            if is_text_model:\n",
    "                texts, labels = batch\n",
    "                input_ids = texts['input_ids'].squeeze(1).to(device)\n",
    "                attention_mask = texts['attention_mask'].squeeze(1).to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(input_ids, attention_mask)  # 传递正确的参数\n",
    "            else:\n",
    "                # 如果是图像模型\n",
    "                images, labels = batch\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "            # 重置梯度\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 前向传播\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 反向传播和优化\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(dataloader)}], Loss: {loss.item()}')\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}] Finished Training')\n",
    "\n",
    "def evaluate_model(model, dataloader, is_text_model=False):\n",
    "    model_type = \"Text\" if is_text_model else \"Image\"\n",
    "    model.eval()  # 将模型设置为评估模式\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            if is_text_model:\n",
    "                texts, labels = batch\n",
    "                input_ids = texts['input_ids'].squeeze(1).to(device)\n",
    "                attention_mask = texts['attention_mask'].squeeze(1).to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "            else:\n",
    "                images, labels = batch\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the {model_type} Model on the validation set: {accuracy} %')\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "text_model = TextOnlyModel().to(device)\n",
    "image_model = ImageOnlyModel().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "text_optimizer = Adam(text_model.parameters(), lr=1e-4)\n",
    "image_optimizer = Adam(image_model.parameters(), lr=1e-4)\n",
    "\n",
    "# 训练和评估\n",
    "train_model(text_model, text_only_train_dataloader, criterion, text_optimizer, is_text_model=True)\n",
    "evaluate_model(text_model, text_only_train_dataloader, is_text_model=True)\n",
    "\n",
    "\n",
    "train_model(image_model, image_only_train_dataloader, criterion, image_optimizer)\n",
    "evaluate_model(image_model, image_only_train_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
